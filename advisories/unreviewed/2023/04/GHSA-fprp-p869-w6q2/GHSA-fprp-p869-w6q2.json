{
  "schema_version": "1.4.0",
  "id": "GHSA-fprp-p869-w6q2",
  "modified": "2023-04-05T03:30:17Z",
  "published": "2023-04-05T03:30:17Z",
  "aliases": [
    "CVE-2023-29374"
  ],
  "details": "In LangChain through 0.0.131, the LLMMathChain chain allows prompt injection attacks that can execute arbitrary code via the Python exec method.",
  "severity": [

  ],
  "affected": [

  ],
  "references": [
    {
      "type": "ADVISORY",
      "url": "https://nvd.nist.gov/vuln/detail/CVE-2023-29374"
    },
    {
      "type": "WEB",
      "url": "https://github.com/hwchase17/langchain/issues/1026"
    },
    {
      "type": "WEB",
      "url": "https://github.com/hwchase17/langchain/issues/814"
    },
    {
      "type": "WEB",
      "url": "https://github.com/hwchase17/langchain/pull/1119"
    },
    {
      "type": "WEB",
      "url": "https://twitter.com/rharang/status/1641899743608463365/photo/1"
    }
  ],
  "database_specific": {
    "cwe_ids": [

    ],
    "severity": null,
    "github_reviewed": false,
    "github_reviewed_at": null,
    "nvd_published_at": "2023-04-05T02:15:00Z"
  }
}